{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cc6fc1-b75a-4c8b-ae4e-cf49f2427470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Recognized Speech Into Chunks Cell\n",
    "\n",
    "#Step 2.2: split audio file/ recognized text (with offsetDifference (in ms) between 2 consecutive words indicates new chunk)\n",
    "def splitRecognizedText(wordList, offsetDifference):   #Input: Recognized text word list (with all attributes) | Output: array of arrays, each chunk = 1 array (of words list with their attributes)\n",
    "    chunks=[]\n",
    "    currentChunk=[]\n",
    "\n",
    "    for i in range(len(wordList)):\n",
    "        currentWord= wordList[i]\n",
    "\n",
    "        if i==0:currentChunk.append(currentWord)\n",
    "        else:\n",
    "\n",
    "            currentWordOffset= wordList[i][\"Offset\"]\n",
    "            previousWordOffset= wordList[i-1][\"Offset\"]\n",
    "\n",
    "            if currentWordOffset> (previousWordOffset + offsetDifference):  #indicates new chunk (2.5s difference in offset)\n",
    "                chunks.append(currentChunk)\n",
    "                currentChunk=[]\n",
    "                currentChunk.append(currentWord)\n",
    "\n",
    "            else: currentChunk.append(currentWord)                #current word is still in the same chunk\n",
    "\n",
    "\n",
    "            if (i== len(wordList)-1): chunks.append(currentChunk)  #if this was the last word append the current chunk to chunks\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Step 2.3: Convert chunks (arrays of word dict(s)) to strings \n",
    "def convertChunksToStrings(chunks): #Inputs: list of chunks (array of arrays) (each chunks includes the word objects with attributes)  | Output: list of the actuals strings of each chunk (first word capitalized & with a period at the end of chunk to denote end of chunk)\n",
    "        \n",
    "    def convert1ChunkToString(wordlist):       #Input: list of word objects (with attributes) | Output: string of words put together   \n",
    "        string=\"\"\n",
    "        for i in range(len(wordlist)):\n",
    "            if i==0:\n",
    "                string+= wordlist[i]['Word'].capitalize()    #capitilizing first word (first letter)\n",
    "            else:\n",
    "                string+= \" \" + wordlist[i]['Word'] \n",
    "        \n",
    "        string+=\". \"  #add a period to denote end of chunk\n",
    "        return(string)\n",
    "    \n",
    "    \n",
    "    chunksStringsList=[]\n",
    "    \n",
    "    for i in range(len(chunks)):\n",
    "        string= convert1ChunkToString(chunks[i])\n",
    "        startTime= chunks[i][0]['Offset']\n",
    "        obj= {'String': string , 'StartTime': startTime}\n",
    "        chunksStringsList.append(obj)\n",
    "    return chunksStringsList\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36de21b-f579-4dea-b468-b5700a5d166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Text From PDF\n",
    "def pdfToText(path):  #Input: PDF file path | Output: list of strings (1 slot per page (text) ) (Slide 1 contents in slot 1 & so on)\n",
    "    import fitz  # this is pymupdf (module used to extract text from pdf)       #perfect way to read text from a pdf (& formatting maintained, include line breaks ('\\n is in string of each slot, but doesn't appear when printing)\n",
    "\n",
    "    with fitz.open(path) as doc:\n",
    "        pages=[0]                             # reserving slot 0 for the no similarity score slide (by adding a 0 as first element so what's appended will start from slot 1 (putting contents of slide 1 in slot 1 for easier representation) in this array\n",
    "        # print(len(doc))                     # gets length of pdf file\n",
    "        for i in range(len(doc)):        \n",
    "            text = doc[i].get_text()          \n",
    "            pages.append(text)\n",
    "    return(pages)\n",
    "\n",
    "\n",
    "def matchSlides(totalSlides, timeArray, wordList):\n",
    "    slides=[]\n",
    "    \n",
    "    for i in range(totalSlides +1): #Create SLides List |  +1, so slide 0 is empty\n",
    "        obj={\"Slide\": i, \"Words\":[], 'ChunksStrings':[]}\n",
    "        slides.append(obj)\n",
    "    \n",
    "\n",
    "    for i in range(len(timeArray)):\n",
    "        startTime= timeArray[i]['Time']\n",
    "\n",
    "        if i==len(timeArray)-1:                 #Last Entry in timeArray\n",
    "            positive_infinity = float('inf')\n",
    "            endTime= positive_infinity\n",
    "        else:\n",
    "            endTime= timeArray[i+1]['Time']\n",
    "\n",
    "\n",
    "        slideNo= timeArray[i]['Slide']\n",
    "\n",
    "        #currentChunk=[]\n",
    "        #currentChunk=[]     # current chunk is a list of word objects (dict(s))\n",
    "\n",
    "        for y in wordList:\n",
    "            if y['Offset']> endTime:\n",
    "                break\n",
    "            if y['Offset']>= startTime and y['Offset']< endTime:\n",
    "                slides[slideNo]['Words'].append(y)\n",
    "    \n",
    "    for i in range(totalSlides +1): #Create SLides List |  +1, so slide 0 is empty\n",
    "        currentSlide= slides[i]\n",
    "        chunks = splitRecognizedText(currentSlide['Words'], 5000)\n",
    "        chunksStrings= convertChunksToStrings( chunks )\n",
    "        currentSlide['ChunksStrings']= chunksStrings\n",
    "        \n",
    "\n",
    "    return(slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa89dbe-c105-427f-9bbf-3e7303b9ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "def sentenceSimilarity(referenceSent, sentences, modelPath): #Input: slideNo (int, slide number), referenceSent (string, slideText comparing to), sentences (list of strings, list of sentences), modelPath (string: path of model either local path or sentence-transformers path) | Output: array of similarity scores (of sentences compared to reference sentence)  \n",
    "\n",
    "    model = SentenceTransformer(modelPath)  \n",
    "    # encode method takes array of strings always\n",
    "    embeddings = model.encode([referenceSent])   \n",
    "    embeddings2 = model.encode(sentences)\n",
    "    \n",
    "    #Cosine similarity first parameter (embedings of reference sentence) must by array of array\n",
    "    x= cosine_similarity( [embeddings[0]] , embeddings2 )  #Let's calculate cosine similarity for source sentence \n",
    "    similarityScores= x[0]                                 #x[0] = array of similarity score of every sentence compared to ref sentence (ref sentence not included)\n",
    "    \n",
    "    return similarityScores\n",
    "\n",
    "def integrateDeepLeaning(slides): #Input: slides ->> list of dict(s) -> {\"Slide\": i, \"Words\":[],   'ChunksStrings':[ {'String': \"\" , 'StartTime': 0}] }\n",
    "    \n",
    "    slidesText= pdfToText('templates/static/lec.pdf')   # array of strings 1 slot per slide\n",
    "    #NOTE: slides & slidesText have slide 0 empty reserved\n",
    "    \n",
    "    \n",
    "    #(Special Cases) (To be done later): 1st (title) slide \n",
    "    \n",
    "    #1) (Implemented in Level 1) don't compare the spoken chunksStrings assigned to that slide to the text of the other slides by -> checking the original slide \n",
    "    #in slideText array if it's boolean variable is true (that this slide is a 1st slide/picture slide) then don't append these chunks/strings to array 1 & 2\n",
    "    #which make up the sentences array together. And append to output array right away (OutputArray -> [  {\"Slide\": i, 'ChunksStrings':[ {'String': \"\" , 'StartTime': 0}] } ]\n",
    "    #Sentences array contains sentences that are compored to every slides' text to find a better match than the original slide it was assigned to)\n",
    "    \n",
    "    #2) (Implemented in Level 2) don't use this slide's text as reference sentence by -> in level 2 for loop we're iterating through the slidesText array \n",
    "    #(text of every slide one by one & using its text as reference sentence and comparing it to the sentence array), so in every iteration check if this slide \n",
    "    #is 1st slide/picture slide (obtained by the boolean variable in slidesText array) if true (that is slide is a 1st slide/picture slide) then skip this iteration/slide\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    #Level 0\n",
    "    #Construct OutputArray -> [  {\"Slide\": i, 'ChunksStrings':[ {'String': \"\" , 'StartTime': 0}] } ] (length: no. of slides + 1 (slot 0 reserved for slide 0) just like slides & slidesText array\n",
    "    \n",
    "    #Level 1\n",
    "    #1)Array 1: Counstruct Array of dict(s) for all chunksStrings across all slides: {String:\"\", StartTime:\"\",  Original SLide: 0, Scores: [ {Slide: 0, Score:0} ] }   \n",
    "    #2)Array 2/ Sentence Array: Construct Arrray of strings for all chunksStrings across all slides (extract it from array 1 (the array of dict(s))\n",
    "\n",
    "    #Level 2\n",
    "    #Reference Sentence: slides text (1 slide at a time) #this way we're going to load model no. of slides times\n",
    "    #Sentneces Array is the array 2 (the array of strings)\n",
    "    #record down similarity score of every string compared to every slide in array1\n",
    "    \n",
    "    #Level 3\n",
    "    #then push strings to the OutputArray -> [  {\"Slide\": i, 'ChunksStrings':[ {'String': \"\" , 'StartTime': 0}] } ] (append from array 1)\n",
    "    #then order by start time & return OutputArray\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------------\n",
    "    #Level 0 (constructing OutputArray)\n",
    "    \n",
    "    OutputArray=[]\n",
    "    for i in range(len(slides)):\n",
    "        obj= {'Slide': i, 'ChunksStrings':[]}\n",
    "        OutputArray.append(obj)\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Level 1 (constructing array 1 & 2 & deciding which chunks/string per slide is going to be appended to compare to other slides & find a better match)\n",
    "    array1=[]\n",
    "    array2=[]\n",
    "    \n",
    "    if len(slides)>1:\n",
    "    \n",
    "        for i in range(1,len(slides)): # x= {\"Slide\": i, \"Words\":[],   'ChunksStrings':[ {'String': \"\" , 'StartTime': 0}] }\n",
    "            x= slides[i]\n",
    "            ChunksStrings= x['ChunksStrings']\n",
    "\n",
    "            #(Special Case) if slide is 1st slide/ title slide do this: (append to output array right away\n",
    "\n",
    "            if i==1:                                    \n",
    "                OutputArray[i]['ChunksStrings']= ChunksStrings\n",
    "\n",
    "            else:\n",
    "\n",
    "                for y in ChunksStrings:    #y = {'String': \"\" , 'StartTime': 0}\n",
    "                    obj= y \n",
    "                    obj['OriginalSlide'] = x['Slide']\n",
    "                    obj['Scores']= []\n",
    "\n",
    "\n",
    "                    array1.append(obj)            \n",
    "                    array2.append(obj['String'])\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------------\n",
    "    #Level 2 (comparing every slides' text, using every slides's text as reference sentence 1 at a time)\n",
    "    #Array 2 is sentences array / 1 slide text at a time is ref sentence (put\n",
    "    \n",
    "    model= 'models/Pyjay-multilingual-snli-v2-500k'\n",
    "   \n",
    "    if len(slidesText)>2 and len(array2)>0:\n",
    "        \n",
    "        for i in range(2,len(slidesText)):   #start doing this from slide 2 (& dont do it for slide 1)             \n",
    "\n",
    "            #(Special Case) if current slide in loop is not 1st slide \n",
    "            #{\n",
    "            referenceSentence= slidesText[i]\n",
    "            scores= sentenceSimilarity(referenceSentence, array2, model)  #scores of every sentence/chunkString matched to currrent slide\n",
    "\n",
    "            for j in range(len(scores)):  # j is the index of current chunkString in the big sentences array\n",
    "                obj= {'Slide': i, 'Score': scores[j]}\n",
    "                array1[j]['Scores'].append(obj)\n",
    "            #}  \n",
    "    #-----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #Level 3 \n",
    "    #Array 1 output sample\n",
    "    #[\n",
    "    # {'String': 'ما my هي إيه aim in life. ', 'StartTime': 4820.0, 'OriginalSlide': 1, \n",
    "    #  'Scores': [{'Slide': 1, 'Score': 0.045683645}, {'Slide': 2, 'Score': 0.06524171}, {'Slide': 3, 'Score': 0.37230912}, {'Slide': 4, 'Score': 0.047170453}, {'Slide': 5, 'Score': 0.12556762}, \n",
    "    #             {'Slide': 6, 'Score': 0.10630279}, {'Slide': 7, 'Score': 0.20325503}, {'Slide': 8, 'Score': 0.05992089}, {'Slide': 9, 'Score': 0.09721908}, {'Slide': 10, 'Score': -0.000944698}]} \n",
    "    #  ,   \n",
    "    # {'String': 'Going to the river. ', 'StartTime': 19260.0, 'OriginalSlide': 3, \n",
    "    # 'Scores': [{'Slide': 1, 'Score': 0.060692}, {'Slide': 2, 'Score': 0.17372939}, {'Slide': 3, 'Score': 0.041466802}, {'Slide': 4, 'Score': 0.22299403}, {'Slide': 5, 'Score': 0.048308853}, \n",
    "    #             {'Slide': 6, 'Score': 0.13261351}, {'Slide': 7, 'Score': -0.008525603}, {'Slide': 8, 'Score': 0.009413469}, {'Slide': 9, 'Score': 0.037716635}, {'Slide': 10, 'Score': 0.043555353}]}\n",
    "    \n",
    "    #]\n",
    "    \n",
    "    \n",
    "    #a) Append to output array (to original slide or slide with max score) \n",
    "    for x in array1:\n",
    "        \n",
    "        obj= {'String':  x['String'] , 'StartTime': x['StartTime'] }\n",
    "        \n",
    "        originalSlideNo= x['OriginalSlide']\n",
    "        scores= x['Scores']\n",
    "        \n",
    "        maxScore=0\n",
    "        maxScoreSlideNo=0\n",
    "        \n",
    "        for y in scores:\n",
    "            score= y['Score']\n",
    "            slideNo= y['Slide']\n",
    "            if score> maxScore:\n",
    "                maxScore= score\n",
    "                maxScoreSlideNo= slideNo\n",
    "        \n",
    "        #got max score & max score slide No\n",
    "        \n",
    "        if maxScore==0:   #append to original slide if max similarity score is 0\n",
    "            OutputArray[originalSlideNo]['ChunksStrings'].append(obj)\n",
    "        \n",
    "        else:  #append to slide with max similarity score \n",
    "            OutputArray[maxScoreSlideNo]['ChunksStrings'].append(obj)\n",
    "                  \n",
    "    #b) Ordering chunksStrings by start time\n",
    "    \n",
    "    for x in OutputArray:\n",
    "        chunksStrings= x['ChunksStrings']\n",
    "        \n",
    "        from operator import itemgetter\n",
    "        newlist = sorted(chunksStrings, key=itemgetter('StartTime')) \n",
    "        x['ChunksStrings'] = newlist\n",
    "            \n",
    "    print()\n",
    "    print(\"Array1\")\n",
    "    display(array1)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    return OutputArray\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8004ad4e-333a-4841-9912-cd1fb39c79c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Speech to Text Cell  (New Speech To Text)\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "\n",
    "#Common\n",
    "def display(list1):                         ### Input: array of Words (dict)  | Output: prints every slot in seperate line\n",
    "    for x in list1:\n",
    "        print(x)\n",
    "    print()\n",
    "\n",
    "def stringifyWordList(wordlist):                     ### Input: array of Words (dict) | Output: string (readable form of word array)  \n",
    "    string=\"\"\n",
    "    for i in range(len(wordlist)):\n",
    "        string+= wordlist[i]['Word'] + \" \"\n",
    "\n",
    "        #Line Breaks on Each Language Switch {\n",
    "        #if i<len(wordlist)-1 :\n",
    "        #    if wordlist[i]['Language']!= wordlist[i+1]['Language']:\n",
    "        #        string += '\\n'\n",
    "        #}\n",
    "\n",
    "    #return (\"Output >>> \\n\" +string)       # you need to print something english first, in case the first word is arabic becuase if is python will print from right to left (the whole output, becuase it detected arabic printout)\n",
    "    string += \"\\n\"\n",
    "    return(string)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Continous Speech To Text Recognition\n",
    "def speech_recognize_continuous_from_file(filePath):         ### Input: audio file path  | Output: dict {English (Word Array), Arabic (Word Array), Combined Ordered (Word Array), Overlap Filtered (Word Array), Overlap Filteration Debugging (String Array) }\n",
    "                                                                                                      # word array -> word is a dict with all attributes\n",
    "\n",
    "    #Helper Methods\n",
    "    \n",
    "    def getMinOffset(words):               #keeps getting the current minumum offset of the word list\n",
    "        minIndex=0\n",
    "        minOffset= words[0]['Offset']\n",
    "        for i in range(len(words)):\n",
    "            if words[i]['Offset']<minOffset:\n",
    "                minIndex=i\n",
    "                minOffset= words[i]['Offset']\n",
    "        return minIndex\n",
    "\n",
    "    \n",
    "    def ordering(words):                  #orders list by offset (gets current min offset & pops it from the old list & adds it to the new list)\n",
    "        newWords=[]\n",
    "        for i in range(len(words)):\n",
    "            minIndex= getMinOffset(words)\n",
    "            obj= words.pop(minIndex)\n",
    "            newWords.append(obj)\n",
    "        return newWords\n",
    "    \n",
    "    \n",
    "        \n",
    "    def overlapFilteration(words, overlapPercentage1, confidenceDifference1):      #words is list of orders words dict(s) \n",
    "        newWords=[]      \n",
    "        overlapDebug=[]\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            chosenWords=[]\n",
    "            \n",
    "            currentWord= words[i]\n",
    "            currentWordOffset= currentWord['Offset']\n",
    "            currentWordConfidence= currentWord['Confidence']\n",
    "            currentWordDuration= currentWord['Duration']\n",
    "\n",
    "\n",
    "            if i== 0:                          #if the currrent word is the first word just append it to the new list\n",
    "                newWords.append(currentWord)\n",
    "                \n",
    "\n",
    "            else:                                        #comparing the current word with the word after it\n",
    "                prevWord= newWords.pop()\n",
    "                prevWordOffset= prevWord['Offset']\n",
    "                prevWordConfidence= prevWord['Confidence']\n",
    "                prevWordDuration= prevWord['Duration']\n",
    "\n",
    "                overlap= prevWordOffset + prevWordDuration - currentWordOffset\n",
    "                overlapPercentage= (overlap / currentWordDuration) * 100               ##overlap percentage of currentword duration\n",
    "                confidenceDiff= abs(currentWordConfidence-prevWordConfidence)\n",
    "                \n",
    "                if overlapPercentage >= overlapPercentage1 and confidenceDiff > confidenceDifference1:        ###   Main If condition 1\n",
    "\n",
    "                    if prevWordConfidence > currentWordConfidence :\n",
    "                        newWords.append(prevWord)\n",
    "                        chosenWords.append(prevWord['Word'])\n",
    "\n",
    "                    else:\n",
    "                        newWords.append(currentWord)\n",
    "                        chosenWords.append(currentWord['Word'])\n",
    "\n",
    "\n",
    "                else:\n",
    "                    newWords.append(prevWord)\n",
    "                    chosenWords.append(prevWord['Word'])\n",
    "                    \n",
    "                    newWords.append(currentWord)\n",
    "                    chosenWords.append(currentWord['Word'])\n",
    "\n",
    "                    \n",
    "                debug= \"Overlap Comparison -> Prev Word: \" + str(prevWord['Word']) +\" | Current Word: \" + str(currentWord['Word']) + \" | Confidence Difference: \" + \"{:.2f}\".format(confidenceDiff) +  \" | Overlap Percentage: \" + str(overlapPercentage) + \" | Chosen Word(s): \" + str(chosenWords) +  \"\\n\"  \n",
    "                overlapDebug.append(debug)\n",
    "                \n",
    "    \n",
    "        return {\"Words\": newWords , \"Debug\": overlapDebug}\n",
    "\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    words=[]\n",
    "    \n",
    "    def recognizeLanguage(language):   # appends the recognized words (according to language given) to 'words' \n",
    "        \n",
    "        wordsList=[]\n",
    "        \n",
    "        speech_config = speechsdk.SpeechConfig(subscription=\"0915a529a519455daa5e8dfce0a921df\", region=\"southafricanorth\")\n",
    "        speech_config.speech_recognition_language=language                                                                     #Language Here\n",
    "        speech_config.set_service_property(\"wordLevelConfidence\",\"true\", speechsdk.ServicePropertyChannel.UriQueryParameter)\n",
    "        speech_config.request_word_level_timestamps()      #Gets offset & duration of each word                                             \n",
    "        speech_config.set_profanity(speechsdk.ProfanityOption.Removed)  #Removes profane words\n",
    "        speech_config.set_service_property(\"format\",\"detailed\", speechsdk.ServicePropertyChannel.UriQueryParameter)\n",
    "\n",
    "        audio_config = speechsdk.audio.AudioConfig(filename=filePath)                                                         #path of file here\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "\n",
    "        #Stop Callback\n",
    "        done = False\n",
    "        def stop_cb(evt):\n",
    "            \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "            #print('CLOSING on {}'.format(evt))\n",
    "            nonlocal done\n",
    "            done = True\n",
    "\n",
    "        #Handle Recognized Speech Envent\n",
    "        def handleResult(evt):          #handles result of every small output\n",
    "            r= evt.result\n",
    "            output= json.loads(r.json)['NBest'][0]            # the display text of the result is always associated with ['NBest'][0]       \n",
    "            \n",
    "            currentText= r.text \n",
    "            currentWords=output['Words']\n",
    "            currentWords2=[]\n",
    "            \n",
    "            for x in currentWords:                           #Simplfying word array at the smallest level (each small output alone, simmplfying before adding to big array)\n",
    "                wordLength= len(x['Word'])\n",
    "                \n",
    "                if wordLength>1:                              #Eliminating words with length 1 (alphabets on their own) ('و' is always appended to next word)\n",
    "                    x['Offset']= x['Offset']* 10**-4\n",
    "                    x['Duration']= x['Duration']* 10**-4\n",
    "                    x['Confidence']= x['Confidence']* 10**2\n",
    "                    x['Language']= language\n",
    "                    currentWords2.append(x)\n",
    "              \n",
    "                ##Here you can update the x['Word'] by the word in currentText (r.text) (display text) to add punctuation (but there are some cases like apostrophe you need to take care of)\n",
    "           \n",
    "     \n",
    "            def confidenceThreshold(percentage, currentWords):           # Input: confidence threshold percentage & list of words (dict(s))  | Output: filtered list of words       \n",
    "                newCurrentWords=[]\n",
    "                for x in currentWords:\n",
    "                    if x['Confidence'] > percentage:\n",
    "                        newCurrentWords.append(x)\n",
    "                return newCurrentWords\n",
    "           \n",
    "            currentWords2= confidenceThreshold(5, currentWords2)            #Confidence Threshold Filteration at the simplest level (current 5%)\n",
    "            wordsList.extend(currentWords2)\n",
    "            \n",
    "            #print()\n",
    "            #print(r.text)          #Display Text of Result (with punctuation)\n",
    "            #print(currentWords)   #List of each word in the display text with a confidence rate\n",
    "            \n",
    "        \n",
    "\n",
    "        #Recognized Speech\n",
    "        speech_recognizer.recognized.connect(lambda evt: handleResult(evt) )   # only occurs if speech is recognized (r.reason == speechsdk.ResultReason.RecognizedSpeech) (so you don't need to handle the speech not recognized condition\n",
    "\n",
    "        # Stopping Conditions (of continous speech recognition-> either session stopped or canceled events\n",
    "        speech_recognizer.session_stopped.connect(stop_cb)\n",
    "        speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "        # Start continuous speech recognition\n",
    "        speech_recognizer.start_continuous_recognition()\n",
    "        \n",
    "       \n",
    "        #Delay between code\n",
    "        while not done:\n",
    "            time.sleep(.5)\n",
    "        \n",
    "        # Stop continuous speech recognition & Return output\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        \n",
    "        return wordsList \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #English\n",
    "    english = recognizeLanguage(\"en-US\")\n",
    "    \n",
    "    #Arabic\n",
    "    arabic = recognizeLanguage(\"ar-EG\")\n",
    "    \n",
    "    #Recognizing English Only\n",
    "    #arabic=[]\n",
    "    \n",
    "    words= english + arabic \n",
    "    \n",
    "    #--------------------------------------------\n",
    "    words = ordering(words)\n",
    "    overlapFilter = overlapFilteration(words, 40, 5)  # 40%  is the overlap filteration percentage, 5% is the confidence difference # if there's if 40% overlap between 2 words & confidence difference is greater than 5%, overlap filertation will occur & the higher confidence word will be chosen\n",
    "    \n",
    "    newWords  = overlapFilter['Words'] \n",
    "    newWordsDebug  = overlapFilter['Debug'] \n",
    "    \n",
    "    return {'English': english , 'Arabic': arabic , 'Ordered': words , 'Overlap Filtered': newWords , 'Overlap Debug': newWordsDebug}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c5e23e9-e97c-4171-9faa-f181863a924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speech to Text Cell 2 (Continous Speech Recognition, with continous language detection #not natural needs to pause for 1 sec when code switching\n",
    "#Link: https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/language-identification?tabs=once&pivots=programming-language-python\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def speech_recognize_continuous_from_file2(filePath): \n",
    "    #Stop Callback\n",
    "    def stop_cb(evt):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        #print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    #Handle Recognized Speech Envent\n",
    "\n",
    "\n",
    "    \n",
    "    endpoint_string = \"wss://{}.stt.speech.microsoft.com/speech/universal/v2\".format(\"southafricanorth\")\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=\"0915a529a519455daa5e8dfce0a921df\", endpoint=endpoint_string)\n",
    "    speech_config.set_property(property_id=speechsdk.PropertyId.SpeechServiceConnection_ContinuousLanguageIdPriority, value='Latency')\n",
    "    speech_config.set_service_property(\"wordLevelConfidence\",\"true\", speechsdk.ServicePropertyChannel.UriQueryParameter)\n",
    "    speech_config.request_word_level_timestamps()      #Gets offset & duration of each word                                             \n",
    "    speech_config.set_profanity(speechsdk.ProfanityOption.Removed)  #Removes profane words\n",
    "    speech_config.set_service_property(\"format\",\"detailed\", speechsdk.ServicePropertyChannel.UriQueryParameter)\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=filePath)                                                         #path of file here\n",
    "    \n",
    "    auto_detect_source_language_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(languages=[\"en-US\", \"ar-EG\"])\n",
    "    \n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, auto_detect_source_language_config=auto_detect_source_language_config, audio_config=audio_config)\n",
    "\n",
    "\n",
    "    #Stop Callback\n",
    "    done = False\n",
    "\n",
    "    stringList=[]\n",
    "    \n",
    "    def handleResult(evt):          #handles result of every small output\n",
    "        r= evt.result\n",
    "        #print(r.text)\n",
    "        #output= json.loads(r.json)['NBest'][0]            # the display text of the result is always associated with ['NBest'][0]       \n",
    "        stringList.append(r.text)\n",
    "        \n",
    "    \n",
    "\n",
    "    #Recognized Speech\n",
    "    speech_recognizer.recognized.connect(lambda evt: handleResult(evt) )  # only occurs if speech is recognized (r.reason == speechsdk.ResultReason.RecognizedSpeech) (so you don't need to handle the speech not recognized condition\n",
    "\n",
    "    # Stopping Conditions (of continous speech recognition-> either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "\n",
    "    #Delay between code\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    # Stop continuous speech recognition & Return output\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "    string=\"\"\n",
    "    for x in stringList:\n",
    "        string+= x + \" \"\n",
    "        \n",
    "    print(string)    \n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6cd32cd-ed3e-4eb6-89df-3f5c29100599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match Notes to pdf file (with iteration)\n",
    "\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "import io\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont \n",
    "\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "\n",
    "\n",
    "def getPageSize(path, pageNo):\n",
    "    pdf = PdfFileReader(open(path, 'rb'))\n",
    "    page_1 = pdf.getPage(pageNo)\n",
    "    if page_1.get('/Rotate', 0) in [90, 270]:\n",
    "        return page_1['/MediaBox'][2], page_1['/MediaBox'][3]\n",
    "    else:\n",
    "        return page_1['/MediaBox'][3], page_1['/MediaBox'][2]\n",
    "    \n",
    "    \n",
    "def outputPDF(path, strings):          #Input: path -> pdf file path, strings -> list of strings (first entry is the notes of 1st slide directly no slide 0) | Output: new pdf file with notes added (destination.pdf)\n",
    "    \n",
    "    originalPDF = PdfFileReader(open(path, \"rb\"))\n",
    "    totalpages = originalPDF.numPages\n",
    "\n",
    "    output = PdfFileWriter()\n",
    "\n",
    "    \n",
    "    #inside loop\n",
    "    for j in range(totalpages): #iterate over each slide\n",
    "                \n",
    "        slideNotes= strings[j] #1 string       #notes of corrosponding slide\n",
    "        \n",
    "        #split slide notes on 100 charchters (on spaces)\n",
    "        \n",
    "        \n",
    "        stringsList=[]\n",
    "        counter=0\n",
    "        currentString=\"\"\n",
    "\n",
    "        for i in range(len(slideNotes)): \n",
    "            currentCharacter = slideNotes[i]\n",
    "\n",
    "            if counter<120:\n",
    "                currentString+= currentCharacter\n",
    "                counter+=1\n",
    "            else:\n",
    "                if currentCharacter!= \" \":\n",
    "                   currentString+= currentCharacter\n",
    "                   counter+=1\n",
    "                else:                                  #stopiing condition 1\n",
    "                    currentString+= currentCharacter\n",
    "                    stringsList.append(currentString)\n",
    "                    counter=0\n",
    "                    currentString= \"\"\n",
    "\n",
    "            if i==len(slideNotes)-1:   #stoppiing condition 2\n",
    "                stringsList.append(currentString)\n",
    "                    \n",
    "            \n",
    "        #now string of slide is split into 100 character strings in strings list array\n",
    "                       \n",
    "        h,w=getPageSize(path,j)\n",
    "       \n",
    "                \n",
    "        #Create New Page\n",
    "        addedHeight= 45 + (15* len(stringsList) )\n",
    "        packet = io.BytesIO()\n",
    "        can = canvas.Canvas(packet, pagesize=  (w, h + addedHeight)   )           # page size= (w,h)\n",
    "        \n",
    "        #can.setStrokeColorRGB(0,0,1)\n",
    "        can.rect(65,5,w-130,addedHeight-10, fill=0)\n",
    "        \n",
    "        currentHeight= addedHeight-20\n",
    "        can.setFillColorRGB(0,0,1)\n",
    "        \n",
    "       \n",
    "        pdfmetrics.registerFont(TTFont('arial', 'assets/arial.ttf'))\n",
    "        can.setFont('arial', 12)\n",
    "        can.drawString(75, currentHeight, \"NOTES\")\n",
    "        currentHeight-=25\n",
    "        \n",
    "        can.setFillColorRGB(0,0,0)\n",
    "        for x in stringsList:\n",
    "            x= \"I      \" + x\n",
    "            ar = arabic_reshaper.reshape(x)\n",
    "            ar = get_display(ar)\n",
    "            can.drawString(75, currentHeight,  ar)\n",
    "            currentHeight-=15\n",
    "            \n",
    "        can.save()\n",
    "        packet.seek(0)\n",
    "        new_pdf = PdfFileReader(packet)\n",
    "\n",
    "        page = new_pdf.getPage(0)\n",
    "        page.mergeScaledTranslatedPage( originalPDF.getPage(j) , 1 , 0 , addedHeight)    #merge old page with new page (so the page would have the size of new page)\n",
    "\n",
    "        output.addPage(page)\n",
    "   \n",
    "    \n",
    "    #out of loop\n",
    "    outputStream = open(\"destination.pdf\", \"wb\")\n",
    "    output.write(outputStream)\n",
    "    outputStream.close()\n",
    "\n",
    "\n",
    "    \n",
    "def convertToStringPerSlide(list1): # Input -> [  {\"Slide\": i, 'ChunksStrings':[ {'String': \"\" , 'StartTime': 0}] } ] (length: no. of slides + 1 (slot 0 reserved for slide 0) \n",
    "    strings=[]\n",
    "    for x in list1:\n",
    "        chunks= x['ChunksStrings']\n",
    "        currentString=\"\"\n",
    "        for y in chunks:\n",
    "            currentString1= y['String']\n",
    "            currentString+= currentString1 + \" \"\n",
    "        strings.append(currentString)\n",
    "   \n",
    "    return strings\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb940fc-079d-4a7e-9837-9bad627a0755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [01/Jul/2022 23:19:18] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jul/2022 23:19:24] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jul/2022 23:19:38] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jul/2022 23:19:47] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file uploaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-07-01 23:21:01,726] ERROR in app: Exception on /uploadAudio [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1953, in full_dispatch_request\n",
      "    return self.finalize_request(rv)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1968, in finalize_request\n",
      "    response = self.make_response(rv)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2127, in make_response\n",
      "    raise TypeError(\n",
      "TypeError: The view function did not return a valid response. The return type must be a string, dict, tuple, Response instance, or WSGI callable, but it was a int.\n",
      "127.0.0.1 - - [01/Jul/2022 23:21:01] \"POST /uploadAudio HTTP/1.1\" 500 -\n",
      "[2022-07-01 23:21:01,734] ERROR in app: Exception on /uploadTimeArray [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1953, in full_dispatch_request\n",
      "    return self.finalize_request(rv)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1968, in finalize_request\n",
      "    response = self.make_response(rv)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2097, in make_response\n",
      "    raise TypeError(\n",
      "TypeError: The view function did not return a valid response. The function either returned None or ended without a return statement.\n",
      "127.0.0.1 - - [01/Jul/2022 23:21:01] \"POST /uploadTimeArray HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'Time': 0, 'Slide': 1}\n",
      "{'Time': 10494, 'Slide': 2}\n",
      "{'Time': 35293, 'Slide': 3}\n",
      "{'Time': 50602, 'Slide': 4}\n",
      "\n",
      "\n",
      "Array1\n",
      "{'String': 'ده the في first law of newton بيقول إن يبقى body is at rest or يتحرك بسرعة ثابتة إن in straight line هتفضل or هتفضل تتحرك إن in straight line at constant speed unless it is acted upon by force. ', 'StartTime': 14350.0, 'OriginalSlide': 2, 'Scores': [{'Slide': 2, 'Score': 0.81207037}, {'Slide': 3, 'Score': 0.40498498}, {'Slide': 4, 'Score': 0.40445456}]}\n",
      "{'String': 'ده the second law of newton إذا quantitative description of the changes that can produce on the motion of her body. ', 'StartTime': 38860.0, 'OriginalSlide': 3, 'Scores': [{'Slide': 2, 'Score': 0.4088407}, {'Slide': 3, 'Score': 0.8290877}, {'Slide': 4, 'Score': 0.5953171}]}\n",
      "{'String': 'The third law of newton states that when two bodies interact they apply forces to one another ده طبعا are equal in magnitude and opposite in direction. ', 'StartTime': 53350.0, 'OriginalSlide': 4, 'Scores': [{'Slide': 2, 'Score': 0.4237818}, {'Slide': 3, 'Score': 0.65732485}, {'Slide': 4, 'Score': 0.91232014}]}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Jul/2022 23:22:30] \"GET /result HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Today's our first physics lecture and we're going to talk about the three newton laws وإزاي هما بيأثروا علينا.  \", 'ده the في first law of newton بيقول إن يبقى body is at rest or يتحرك بسرعة ثابتة إن in straight line هتفضل or هتفضل تتحرك إن in straight line at constant speed unless it is acted upon by force.  ', 'ده the second law of newton إذا quantitative description of the changes that can produce on the motion of her body.  ', 'The third law of newton states that when two bodies interact they apply forces to one another ده طبعا are equal in magnitude and opposite in direction.  ']\n"
     ]
    }
   ],
   "source": [
    "#Website\n",
    "\n",
    "from flask import Flask, render_template, request, redirect, flash, session, url_for, send_from_directory\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "app._static_folder = \"templates/static\"\n",
    "\n",
    "\n",
    "@app.route('/', methods = ['GET', 'POST'])\n",
    "def first():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        f.save(secure_filename(\"lec.pdf\"))\n",
    "        os.replace(\"lec.pdf\", \"templates/static/lec.pdf\")  #moving uploaded pdf to correct directory that can be accible by html\n",
    "        return render_template(\"index.html\",data=1)\n",
    "    else:\n",
    "        return render_template('upload.html')\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/uploadAudio\", methods=['POST', 'GET'])\n",
    "def index():\n",
    "    if request.method == \"POST\":\n",
    "        f = request.files['audio_data']\n",
    "        f.save(secure_filename('assets/audioFile.wav'))\n",
    "        print('file uploaded successfully')\n",
    "        \n",
    "        #------------------------------------\n",
    "        #Resampling audio file to 44.1khz && saving file as <assets/audioFile.wav>\n",
    "        file='assets/audioFile.wav'\n",
    "        import librosa    \n",
    "        import soundfile\n",
    "        t, sr = librosa.load(file, sr= 44100)\n",
    "        soundfile.write('assets/audioFile.wav', t, sr)\n",
    "        #-------------------------------------\n",
    "        return 0\n",
    "    \n",
    "\n",
    "\n",
    "timeArray=[]\n",
    "totalSlides=0\n",
    "\n",
    "\n",
    "#Retrieving data from js \n",
    "@app.route(\"/uploadTimeArray\", methods=['POST', 'GET'])\n",
    "def test():\n",
    "\n",
    "    response = request.data.decode(\"utf-8\") #decode to convert bytes to strings\n",
    "    response = json.loads(response)     #json parsing (reverting json.stringfy)\n",
    "    \n",
    "    global timeArray              #to update global variable & not make local variable \n",
    "    global totalSlides\n",
    "    \n",
    "    totalSlides= response.pop(0);  # extracting totalslides at index 0 of response\n",
    "    timeArray= response;\n",
    "   \n",
    "  \n",
    "@app.route('/result')\n",
    "def result():    \n",
    "    \n",
    "    file='assets/audioFile.wav'\n",
    "    global timeArray\n",
    "    global totalSlides\n",
    "    \n",
    "    print()\n",
    "    display(timeArray)\n",
    "    \n",
    "    #------------------------------------------------------------------------\n",
    "    #Speech Recognition 1\n",
    "    output= speech_recognize_continuous_from_file(file)\n",
    "    wordListOrdered= output['Ordered']\n",
    "    wordList= output['Overlap Filtered']\n",
    "    \n",
    "    \n",
    "    #Speech Recognition 2\n",
    "    #wordList2= speech_recognize_continuous_from_file2(file) #prints output in console\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    notes = matchSlides(totalSlides, timeArray, wordList) \n",
    "    #for x in notes:          #Display Notes\n",
    "    #    print(\"Slide: \" +  str(x['Slide'] ) ) \n",
    "    #    display(x['ChunksStrings'])\n",
    "\n",
    "    \n",
    "   \n",
    "    #print(\"WordList\")\n",
    "    #display(wordList)\n",
    "    #print()\n",
    "    \n",
    "    #print(\"WordList Before Overlap\")\n",
    "    #display(wordListOrdered)\n",
    "    \n",
    "    notes2= integrateDeepLeaning(notes)  # output-> [  {\"Slide\": i, 'ChunksStrings':[ {'String': \"\" , 'StartTime': 0}] } ] (length: no. of slides + 1 (slot 0 reserved for slide 0) \n",
    "    \n",
    "    str1= convertToStringPerSlide(notes2)\n",
    "    str1.pop(0) #remove slote 0 (reserved for slide 0 , slide not in pdf)\n",
    "    outputPDF(\"templates/static/lec.pdf\", str1)\n",
    "    print(str1)\n",
    "    \n",
    "    #change notes 2 to each slide having 1 string of notes (array of strings with the order of the slides, no slot reserved for slide 0, which doesn't exist)\n",
    "    \n",
    "    #print()\n",
    "    #print(\"Integrate Deep Learning\")\n",
    "    #display(notes2)\n",
    "  \n",
    "    #return render_template('output.html', data=notes2)\n",
    "    workingdir = os.path.abspath(os.getcwd())\n",
    "    return send_from_directory(workingdir, 'destination.pdf')\n",
    "\n",
    "\n",
    "#test method to show pdf in browser through flask\n",
    "@app.route('/result2')\n",
    "def result2(): \n",
    "    workingdir = os.path.abspath(os.getcwd())\n",
    "    \n",
    "    return send_from_directory(workingdir, 'destination.pdf')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   app.run(debug = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
